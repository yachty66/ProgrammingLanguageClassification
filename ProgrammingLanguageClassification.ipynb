{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efbc684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build using LSTM\n",
    "#LSTM are used for sequential data\n",
    "#sequential data = order of data matters\n",
    "#use this tutorial https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n",
    "'''\n",
    "1. convert language to numeric label \n",
    "2. get an tokenizer for programming languages\n",
    "3. tokenize all of my code\n",
    "4. create pipelines\n",
    "5. Dataloader\n",
    "6. define model \n",
    "7. initiate instance\n",
    "8. define functions to train the model and evaluate results\n",
    "9. split dataset and run the model\n",
    "10. Evaluate the model with test dataset\n",
    "11. \n",
    "\n",
    "stuck\n",
    "Problem:\n",
    "    habe dataset and have to convert one column to tokens, the creation of this tokens should make sense print() as token = p,r,i,nt,() does not make sense but print, ()\n",
    "    given is my training dataset with originally 3 columns\n",
    "    my code colum is the column which needs to be tokenized\n",
    "    the code is in a structure of several words\n",
    "    i need to find out how i can tokenize the code based on that I can train a model which identifies pattersn like how which combinations of which tokens identify a certain label\n",
    "    i also have to encode my target \"language\" to some numerical value\n",
    "    i need an tokenizer who is specific for programmign languages\n",
    "    I can get for every cell a list of the tokenized code, is that what i want? check in standard code if this has the same structure there\n",
    "    \n",
    "Plan:\n",
    "    1. structure code (comments)\n",
    "    2. fix bug of \"too many values to unpack (expected 2)\" so that I can transform my vocab to numbers to proceed\n",
    "    \n",
    "Problem:\n",
    "    need to convert code column to tokens\n",
    "Plan:\n",
    "    1. iterate over code column andassign every cell new token value\n",
    "        Problem:\n",
    "            cannot manipulate dataframe with item = token\n",
    "        Plan:\n",
    "            (do everything with the test dataset \"test\" of 100 rows)\n",
    "            0. structure code\n",
    "            1. Google: How to create a copy of a dataframe and change his values\n",
    "            2. get index of current row and than access item with info about column and row and convert item to token\n",
    "            3. replacement..\n",
    "                Problem:\n",
    "                    i wanna replace a list of size 1 with an list > 1 which is not possible. can i replacer\n",
    "                    \n",
    "                Plan:\n",
    "                    -1 do i later merge the list? checkout in. huggingface how the merge works\n",
    "                    0. google Replacement lists must match in length. Expecting 1 got 72 --> how to replace lists with different lengths in pandas dataframe?\n",
    "                    0.5 create a copy of a dataframe where every cell in the code column holds the encoded tokens\n",
    "                    1. concatenate list at every comma with an Ã„ to list of size one will fail because sometime i need to replace the list again\n",
    "                    2. wait for an answer of stackoverflow https://stackoverflow.com/questions/71697352/how-to-replace-a-value-of-smaller-length-than-one-with-bigger-length-in-pandas-d\n",
    "                    3. check if in the standard modell the column which gets tokenized has also lists with such lengths\n",
    "Plan:\n",
    "    1. convert the whole column of the whole dataset to tokens\n",
    "    2. \n",
    "     \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2117b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from transformers import RobertaTokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ab547667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>code</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14026</td>\n",
       "      <td>var result = testObj1 | testObj2;\\...</td>\n",
       "      <td>c-sharp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12201</td>\n",
       "      <td>///     Initializes a new instance of ...</td>\n",
       "      <td>c-sharp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17074</td>\n",
       "      <td>/*\\n\\n     Explanation :- a user gives a Strin...</td>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21102</td>\n",
       "      <td>int sum = 0;\\n\\n         for (int i = ...</td>\n",
       "      <td>c-plus-plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53065</td>\n",
       "      <td>if (p-&gt;data &lt; min)\\n\\n         {\\n\\n  ...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               code     language\n",
       "0  14026              var result = testObj1 | testObj2;\\...      c-sharp\n",
       "1  12201          ///     Initializes a new instance of ...      c-sharp\n",
       "2  17074  /*\\n\\n     Explanation :- a user gives a Strin...   javascript\n",
       "3  21102          int sum = 0;\\n\\n         for (int i = ...  c-plus-plus\n",
       "4  53065          if (p->data < min)\\n\\n         {\\n\\n  ...            c"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load and read datasets\n",
    "trainData = pd.read_csv(\"data/train.csv\")\n",
    "testData = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "#use only code and language of dataset and (drop Id column)\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2075e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get id from tokenizer which i use\n",
    "CODEBERTA_LANGUAGE_ID = \"huggingface/CodeBERTa-language-id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a5ce5f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(CODEBERTA_LANGUAGE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6094ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData[\"code\"]=trainData[\"code\"].apply(lambda x: tokenizer.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3de195b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                                               code     language\n",
      "0      14026  [0, 278, 722, 758, 272, 2651, 2642, 21, 631, 2...      c-sharp\n",
      "1      12201  [0, 267, 23137, 262, 40719, 349, 426, 925, 465...      c-sharp\n",
      "2      17074  [0, 3718, 203, 203, 262, 1647, 15327, 31411, 3...   javascript\n",
      "3      21102  [0, 267, 664, 3090, 272, 430, 31, 203, 203, 26...  c-plus-plus\n",
      "4      53065  [0, 267, 317, 298, 84, 303, 544, 596, 1591, 13...            c\n",
      "...      ...                                                ...          ...\n",
      "45623  77158  [0, 267, 1104, 272, 1144, 203, 203, 262, 858, ...       python\n",
      "45624  19972  [0, 278, 407, 18, 352, 70, 67, 487, 18, 812, 1...       python\n",
      "45625  45356  [0, 263, 853, 284, 203, 203, 264, 3143, 478, 3...  c-plus-plus\n",
      "45626  20558  [0, 2824, 7963, 87, 31, 203, 203, 1946, 3671, ...         java\n",
      "45627  31300  [0, 267, 5202, 376, 24637, 415, 203, 203, 264,...         java\n",
      "\n",
      "[45628 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0625eafc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
